---
title: "Parallelization in spOccupancy and spAbundance"
author: "Jeffrey W. Doser"
date: "2024 (last update August 5, 2024)"
description: Learn about how to use parallelization to speed up your models 
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{parallelization}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
options(rmarkdown.html_vignette.check_title = FALSE)
knitr::opts_chunk$set(
  comment = "", cache = TRUE
)
```

\newcommand{\bm}{\boldsymbol} 

# Introduction

This vignette describes options for fitting `spOccupancy` and `spAbundance` models in parallel. As of `spOccupancy` v0.8.0 and `spAbundance` v0.2.0, all model-fitting functions have two arguments related to parallelization: `n.omp.threads` and `parallel.chains`. This document will describe what the two arguments do and when to use one vs. the other. I wrote this short article just to give a bit more detail on the two forms of parallelization and in what situations one approach might be better than the other. 

# `parallel.chains` vs. `n.omp.threads`

The arguments `parallel.chains` and `n.omp.threads` both focus on fitting models in parallel to speed up model run times, but they do so in completely different ways. The newer `parallel.chains` argument is likely the form of parallelization that most users of JAGS, Stan, and/or NIMBLE are most familiar with. When setting `parallel.chains = TRUE`, the `n.chains` MCMC chains specified in the function arguments will be run simultaneously in parallel across different cores. Thus, if you set `n.chains = 3` and `parallel.chains = TRUE`, your computer will attempt to initiate three cores to run each of the individual MCMC chains. This results in substantial improvements in run time as opposed to running the MCMC chains sequentially. The downside to using `parallel.chains = TRUE` is that the model progress that is normally printed to the screen when `verbose = TRUE` will no longer show up. To get a sense of how long a model run in parallel will take, you can pretty simply just run a single MCMC chain of the model for a few iterations, see how long that takes, and then multiply that number accordingly based on the total number of MCMC iterations you plan on running for the full model run. This will not be a perfect representation of model run time, but it should give a general sense of how long the parallel model will take to run.  

The `n.omp.threads` argument implements *within-chain* parallelization using OpenMP. The situations in which `n.omp.threads` will lead to improvements in model performance are a bit more nuanced than when using `parallel.chains`. **First, `n.omp.threads` only results in changes in model run times for spatial models (i.e., models that include spatial random effects).** The `n.omp.threads` argument is still included in all non-spatial models in both `spOccupancy` and `spAbundance`, but it currently does not do anything, so setting this to any value above 1 will not actually result in any differences in run time. For spatial models, setting `n.omp.threads` to a number greater than 1 can result in fairly substantial decreases in model run time for models that use a Nearest Neighbor Gaussian Process (`NNGP = TRUE`). However, the benefits that this provides will depend on three things: (1) the number of spatial locations; (2) how many neighbors are used in the NNGP approximation; and (3) the number of species (for multi-species models). Generally, increasing `n.omp.threads` to a value greater than 1 (usually a value between 5-10 is the sweet spot) will improve performance more when working with a larger number of spatial locations. This becomes clear when considering how the parallelization is implemented. The within-chain parallellization is done when updating each of the $J$ spatial random effects. Essentially, if running a model with $J$ sites and setting `n.omp.threads = 5`, the model will update $\frac{J}{5}$ of the spatial random effects simultaneously across 5 different cores. The larger $J$ is, the more benefits this provides. Similarly, I have found that the within-chain parallelization will only result in improvements when the number of neighbors is 10 or higher. So, if you're fitting a model with less than 10 neighbors, setting `n.omp.threads` to a value greater than 1 may not result in much (if any) improvements in run time. Lastly, for multi-species models, the more species (or the more factors in spatial factor models) you have, generally the more benefits you will see from using `n.omp.threads` with a value greater than 1.  

# Should I set `parallel.chains = TRUE` and `n.omp.threads` to a value greater than 1?

While perhaps a bit counterintuitive, setting `parallel.chains = TRUE` and `n.omp.threads` > 1 will actually not give improved computational performance, and the resulting model fit may actually take longer than if you did not use any form of parallelization! This is a result of how the parallelization is implemented in the two approaches. I generally do not recommend using both of these arguments together. However, as I will point out later in the document, one can fairly easily run multiple chains in parallel by establishing different R sessions (either via RStudio or via the command line) and running a separate chian in each session, and then within each of those chains `n.omp.threads` can be set. Such an approach does allow you to get the best of both worlds (i.e., maximize both within and across chain parallelization). 

# Which type of parallelization should I use? 

For the large majority of users, `parallel.chains` will provide more decreases in model run time than `n.omp.threads`. For fitting any type of non-spatial model, users should use `parallel.chains`. When fitting spatially-explicit models with tens of thousands of locations, using `n.omp.threads` may also provide substantial improvements in run time, in which case one might want to compare some shorter runs using `parallel.chains` vs. `n.omp.threads` to determine which provides the best speed up. For most users, I recommend first fitting some initial small model runs without using any form of parallelization to just make sure things are running properly. Then, setting `parallel.chains = TRUE` for the full model run is a very easy way to substantially improve model run times for nearly all situations when fitting models in `spOccupancy` or `spAbundance`.   

# A simple example with a single-species spatial occupancy model

Below, I provide some code (without a whole lot of explanation) for fitting and comparing run times for a spatial occupancy model using a simulated data set: (1) no parallelizaition; (2) setting `n.omp.threads = 5`; (3) setting `parallel.chains = TRUE`; and (4) setting `n.omp.threads = 5` and `parallel.chains = TRUE`. Note that I do not recommend doing the final option, and my reason for doing this here is just to show how it can actually substantially slow things down. Note that run times may be different on your machine, but that the relative performance of the four models should be similar across devices.

```{r}
library(spOccupancy)
set.seed(11111)
# Simulate the data (625 spatial locations)
J.x <- 25
J.y <- 25
J <- J.x * J.y
n.rep <- sample(1, J, replace = TRUE)
beta <- c(-1, 0.2, 0.3, -0.3)
p.occ <- length(beta)
alpha <- c(0.3, 0.5)
p.det <- length(alpha)
phi <- 3 / .5
sigma.sq <- 1.5
p.RE <- list()
psi.RE <- list()
sp <- TRUE
cov.model = 'exponential'
x.positive <- FALSE
svc.cols <- 1
n.rep.max <- max(n.rep)

dat <- simOcc(J.x = J.x, J.y = J.y, n.rep = n.rep, beta = beta, alpha = alpha,
              p.RE = p.RE, psi.RE = psi.RE, sigma.sq = sigma.sq, phi = phi, sp = TRUE,
              cov.model = cov.model)

# Package everything up into list for spOccupancy
y <- dat$y
X.p <- dat$X.p
X <- dat$X
coords <- dat$coords

# Package all data into a list
occ.covs <- cbind(X)
colnames(occ.covs) <- c('int', 'occ.cov.1', 'occ.cov.2', 'occ.cov.3')
det.covs <- list(int = X.p[, , 1],
                 det.cov.1 = X.p[, , 2])
data.list <- list(y = y,
                  occ.covs = occ.covs,
                  det.covs = det.covs,
                  coords = coords)

# MCMC settings
n.batch <- 400
batch.length <- 25
n.burn <- 5000
n.thin <- 5
n.chains <- 3

# Priors
prior.list <- list(sigma.sq.ig = c(2, 1),
                   phi.unif = c(3 / 1, 3 / .1))

# Starting values
inits.list <- list(alpha = 0,
                   beta = 0,
                   phi = 3 / .5,
                   sigma.sq = 1,
                   nu = 1,
                   z = apply(y, 1, max, na.rm = TRUE))
# Tuning
tuning.list <- list(phi = 0.5)


# Model 1: no parallelization ---------------------------------------------
out.1 <- spPGOcc(occ.formula = ~ occ.cov.1 + occ.cov.2 + occ.cov.3,
	               det.formula = ~ det.cov.1,
	               data = data.list,
	               n.batch = n.batch,
	               batch.length = batch.length,
	               inits = inits.list,
	               priors = prior.list,
	               accept.rate = 0.43,
	               cov.model = "exponential",
	               tuning = tuning.list,
	               verbose = FALSE,
	               NNGP = TRUE,
                 n.neighbors = 15,
	               n.report = 5,
	               n.burn = n.burn,
	               n.thin = n.thin,
	               n.chains = n.chains,
                 parallel.chains = FALSE,
	               n.omp.threads = 1)

# Model 2: within-chain parallelization ----------------------------------- 
out.2 <- spPGOcc(occ.formula = ~ occ.cov.1 + occ.cov.2 + occ.cov.3,
	               det.formula = ~ det.cov.1,
	               data = data.list,
	               n.batch = n.batch,
	               batch.length = batch.length,
	               inits = inits.list,
	               priors = prior.list,
	               accept.rate = 0.43,
	               cov.model = "exponential",
	               tuning = tuning.list,
	               verbose = FALSE,
	               NNGP = TRUE,
                 n.neighbors = 15,
	               n.report = 5,
	               n.burn = n.burn,
	               n.thin = n.thin,
	               n.chains = n.chains,
                 parallel.chains = FALSE,
	               n.omp.threads = 5)

# Model 3: across chain parallelization ----------------------------------- 
out.3 <- spPGOcc(occ.formula = ~ occ.cov.1 + occ.cov.2 + occ.cov.3,
	               det.formula = ~ det.cov.1,
	               data = data.list,
	               n.batch = n.batch,
	               batch.length = batch.length,
	               inits = inits.list,
	               priors = prior.list,
	               accept.rate = 0.43,
	               cov.model = "exponential",
	               tuning = tuning.list,
	               verbose = FALSE,
	               NNGP = TRUE,
                 n.neighbors = 15,
	               n.report = 5,
	               n.burn = n.burn,
	               n.thin = n.thin,
	               n.chains = n.chains,
                 parallel.chains = TRUE,
	               n.omp.threads = 1)
# Model 4: within and across chain parallelization ------------------------
out.4 <- spPGOcc(occ.formula = ~ occ.cov.1 + occ.cov.2 + occ.cov.3,
	               det.formula = ~ det.cov.1,
	               data = data.list,
	               n.batch = n.batch,
	               batch.length = batch.length,
	               inits = inits.list,
	               priors = prior.list,
	               accept.rate = 0.43,
	               cov.model = "exponential",
	               tuning = tuning.list,
	               verbose = FALSE,
	               NNGP = TRUE,
                 n.neighbors = 15,
	               n.report = 5,
	               n.burn = n.burn,
	               n.thin = n.thin,
	               n.chains = n.chains,
                 parallel.chains = TRUE,
	               n.omp.threads = 5)

# Compare model run times -------------------------------------------------
# Model 1: no parallelization
out.1$run.time
# Model 2: within-chain parallelization (n.omp.threads)
out.2$run.time
# Model 3: across-chain parallelization (parallel.chains = TRUE)
out.3$run.time
# Model 4: within and across chain parallelization
# NOTE: this is far slower than even the model with no parallelization!!!
out.4$run.time
```

We can see in this simple example, using `parallel.chains = TRUE` improved model run time a bit more than using `n.omp.threads = 5`, while using both of them simultaneously did not result in any improvements in run time. 

# Using `n.omp.threads` while running chains in parallel

While using `n.omp.threads` and `parallel.chains` generally does not improve model run time (like we saw in the previous example), that does not mean we cannot use another approach to leverage both forms of parallelization. Doing this will just require us to do a bit more as opposed to using a simple argument in the function. 

Say for example we want to run three chains of our model. Instead of running chains in parallel using `parallel.chains`, we can instead simply run multiple instances of our R script in different R sessions, where in each instance of the script we only run a single chain (i.e., we set `n.chains = 1`). We can then run three different instances of the script simultaneously, which will effectively run the chains in parallel. If we use this approach, we can also set `n.omp.threads` to a value greater than 1, and we will get the benefits of both *within-chain* parallelization and across chain parallelization, which we did not see when trying to use `parallel.chains` and `n.omp.threads` simultaneously. The three instances of the R script should save out the resulting object from the model-fitting function, saving it in a form that allows you to distinguish that chain from the other chains. You will then have to subsequently combine the results from the different chains after running the chains, which admittedly can be a bit tricky, depending on what your objectives our with the analysis. The chains can be run simultaneously in a few different ways. Perhaps the most broadly applicable approach is to run the chains directly from a terminal window using `Rscript` or `R CMD BATCH`, which will be very suitable for people trying to run `spOccupancy` or `spAbundance` models on High Performance Computers. Altneratively, if using `RStudio`, one could simply open up three different RStudio windows, or could leverage the "Background Jobs" tab in a single Rstudio script to easily run multiple instances of the script.

[This GitHub repository](https://github.com/doserjef/Switzerland24-Spatial-Workshop) contains materials from a workshop in which there is an example of how to do this. In particular, the files that start with `12` give an example of how to do this with a multi-species spatial occupancy model. 


