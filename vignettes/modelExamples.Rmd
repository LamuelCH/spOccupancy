---
title: "Fitting single species occupancy models with `spOccupancy`"
author: "Jeffrey W. Doser"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: rmarkdown::html_vignette
bibliography: [references.bib]
biblio-style: apalike
vignette: >
  %\VignetteIndexEntry{modelExamples}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
options(rmarkdown.html_vignette.check_title = FALSE)
knitr::opts_chunk$set(
  comment = ""
)
```

## Introduction

This vignette provides numerous worked examples on fitting single species occupancy models available in the `spOccupancy` R package. We will provide step by step examples on how to fit the following models: 

1. Occupancy model using `PGOcc`. 
2. Spatial occupancy model using `spPGOcc`. 
3. Integrated occupancy model using `intPGOcc`. 
4. Spatial integrated occupancy model using `spIntPGOcc`. 

Statistical details of each model can be found in the Gibbs sampler vignette. Step by step examples on multispecies occupancy models are provided in a separate vignette.  

To get started, we load the `spOccupancy` package, as well as the `coda` package, which we will use for some MCMC diagnostics. 

```{r setup}
library(spOccupancy)
library(coda)
```

## Example data set: Foliage-gleaning birds at Hubbard Brook

As an example data set, we will use data from twelve foliage-gleaning birds collected from point count surveys at Hubbard Brook Experimental Forest (HBEF) in New Hampshire, USA. Specific details on the data set are available on the [Hubbard Brook website](https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-hbr&identifier=178) and @doser2021ICOM. The data are provided in the `spOccupancy` package and are loaded with `data(hbef2015)`. 

```{r}
data(hbef2015)
str(hbef2015)
```

The object `hbef2015` is a list comprised of the detection-nondetection data (`y`), covariates on the occupancy portion of the model (`occ.covs`), covariates on the detection portion of the model (`det.covs`), and the spatial coordinates of each site for use in spatially-explicit models. `hbef2015` contains data on 12 species in the three-dimensional array `y`. Here we will use data on the Ovenbird (OVEN) to display single species models, so let's go ahead and subset the `hbef2015` list to only include data from OVEN. 

```{r}
sp.names <- attr(hbef2015$y, "dimnames")[[1]]
hbef2015$y <- hbef2015$y[sp.names == "OVEN", , ]
table(hbef2015$y)
```

We see OVEN is detected at around half of all site-replicate combinations.

## `PGOcc`: Single species occupancy models

The `PGOcc` function fits single species occupancy models using Polya-Gamma latent variables, which should make it faster than other implementations of occupancy models using a logit link function [@clark2019]. `PGOcc` has the following arguments: 

```{r, eval = FALSE}
PGOcc(occ.formula, det.formula, data, starting, n.samples, priors, 
      n.omp.threads = 1, verbose = TRUE, n.report = 100)
```

The first two arguments, `occ.formula` and `det.formula`, use standard R model syntax to denote the covariates included in the occupancy and detection portions of the model, respectively. Only the left hand side of the formulas are included. The names of variables given in the formulas should correspond to those found in `data`, which is a list consisting of the following tags: `y` (detection-nondetection data), `occ.covs` (occupancy covariates), `det.covs` (detection covariates). `y` should be stored as a sites x replicate matrix, `occ.covs` as a matrix or data frame with site-specific covariate values, and `det.covs` is a list with each list element corresponding to a covariate to include in the detection portion of the model. Covariates on detection can vary by site and/or survey. The `hbef2015` data are already in the required format. Here we will fit a single covariate (Elevation) on occupancy and will include three observational covariates (linear and quadratic day of survey, time of day of survey) on the detection portion of the model. We specify the formulas below 

```{r}
oven.occ.formula <- ~ 1
oven.det.formula <- ~ 1
str(hbef2015)
```

Next, we specify the starting values in `starting`. `PGOcc` will set starting values by default (and report what these values are), but here we will do this explicitly. Starting values are specified in a list with the following tags: `z` (latent occupancy values), `alpha` (detection regression coefficients), `beta` (occupancy regression coefficients). Below we specify lazy starting values for the regression coefficients and set them all to 0, and set starting values for `z` based on the detection-nondetection data matrix.

```{r}
# Number of detection and occupancy parameters 
# + 1 is needed to count the intercept
#p.det <- length(hbef2015$det.covs) + 1
p.det <- 1
#p.occ <- ncol(hbef2015$occ.covs) + 1
p.occ <- 1
oven.starting <- list(alpha = rep(0, p.det), 
		      beta = rep(0, p.occ), 
		      z = apply(hbef2015$y, 1, max, na.rm = TRUE))
```

We will next specify the priors for the occupancy and detection regression coefficients. The Polya-Gamma data augmentation algorithm employed by `spOccupancy` assumes normal priors for both the detection and occupancy regression coefficients. These priors are specified in a list with tags `beta.normal` for occupancy and `alpha.normal` for detection parameters. Each list element is then itself a list, with the first element of the list consisting of the hypermeans for each coefficient to be estimated and the second element of the list consisting of the hypervariances for each coefficient. By default, `spOccupancy` will set the hypermeans to 0 and the hypervariances to 2.72, which corresponds to a relatively flat prior on the probability scale (0, 1) [@broms2016model]. We will use these priors here, but specify them explicitly below

```{r}
oven.priors <- list(alpha.normal = list(mean = rep(0, p.det), 
					var = rep(2.72, p.det)), 
		    beta.normal = list(mean = rep(0, p.occ), 
				       var = rep(2.72, p.occ)))
```

We are now set to run the occupancy model. We run the model for 5000 iterations as specified in the `n.samples` argument. Single species occupancy models are fast, and so we set `n.omp.threads = 1` to indicate we won't use multiple threads to run the model. We set `verbose = TRUE` and `n.report = 1000` to report progress every 1000th MCMC iteration. 

```{r}
n.samples <- 5000
out <- PGOcc(occ.formula = oven.occ.formula, 
	     det.formula = oven.det.formula, 
	     data = hbef2015, 
	     starting = oven.starting, 
	     n.samples = n.samples, 
	     priors = oven.priors, 
	     n.omp.threads = 1, 
	     verbose = TRUE, 
	     n.report = 1000)
str(out)
```

You may see a slightly different message depending on whether or not your computer compiled `spOccupancy` with OpenMP support. We see `PGOcc` returns a list of class `PGOcc` with a suite of different objects, most of them being `coda::mcmc` objects of posterior samples. Notice the "Preparing the data" printed section doesn't have any information in it. `spOccupancy` functions will present warnings when preparing the data for the model in this section, or will print out the default priors or starting values used when they are not specified in the function call. Here we specified everything explicitly so no information was reported. 

For a nice summary of the regression parameters we can use the `summary` function on the resulting `PGOcc` object. The `sub.sample` argument in `summary` for all `spOccupancy` model objects allows us to specify a sub-sample for the results included in the summary by specifying a list with tags `start`, `end`, and `thin`. We won't thin the chains here, but we will eliminate the first 10% of samples as burn-in. If `sub.sample` is not specified, results are summarized across the entire posterior chains.

```{r}
summary(out, sub.sample = list(start = round(.10 * n.samples), n.samples, thin = 1))
```

We see OVEN is fairly prominent in the forest given the large intercept value, and the negative linear and quadratic terms for `Elevation` suggest occurrence probability peaks at mid-elevations. 

### Convergence Diagnostics

The posterior samples in the `PGOcc` object are `coda::mcmc` objects, which we can quickly assess for convergence visually using trace plots. 

```{r, fig.height = 4, fig.width = 4}
plot(out$beta.samples, density = FALSE)
```
```{r, fig.height = 4, fig.width = 4}
plot(out$alpha.samples, density = FALSE)
```

For a complete analysis (i.e., in a peer-reviewed manuscript), we will likely want to more formally check for convergence, perhaps using the Gelman-Rubin R-hat diagnostic. This requires running multiple chains at largely different starting values for the regression parameters. For a single species non-spatial occupancy model, we can accomplish this by running multiple chains sequentially (since they run really fast) with different starting values, then combining the output into a `coda::mcmc.list` object for use the `coda::gelman.diag` function. Notice below we set `verbose = FALSE` to suppress the messages printed by `PGOcc`. 

```{r}
oven.starting <- list(alpha = rep(2, p.det), 
		      beta = rep(2, p.occ), 
		      z = apply(hbef2015$y, 1, max, na.rm = TRUE))
out.2 <- PGOcc(occ.formula = oven.occ.formula, 
	     det.formula = oven.det.formula, 
	     data = hbef2015, 
	     starting = oven.starting, 
	     n.samples = n.samples, 
	     priors = oven.priors, 
	     n.omp.threads = 1, 
	     verbose = FALSE, 
	     n.report = 1000)
oven.starting <- list(alpha = rep(-2, p.det), 
		      beta = rep(-2, p.occ), 
		      z = apply(hbef2015$y, 1, max, na.rm = TRUE))
out.3 <- PGOcc(occ.formula = oven.occ.formula, 
	     det.formula = oven.det.formula, 
	     data = hbef2015, 
	     starting = oven.starting, 
	     n.samples = n.samples, 
	     priors = oven.priors, 
	     n.omp.threads = 1, 
	     verbose = FALSE, 
	     n.report = 1000)
# beta convergence
gelman.diag(mcmc.list(out$beta.samples, out.2$beta.samples, 
		      out.3$beta.samples))
# alpha convergence
gelman.diag(mcmc.list(out$alpha.samples, out.2$alpha.samples, 
		      out.3$alpha.samples))
```

### Posterior Predictive Check 

The function `ppcOcc` performs a posterior predictive check on all `spOccupancy` model objects as Goodness of Fit (GoF) assessment. The fundamental idea of a posterior predictive check is as follows: our model should generate data that closely align with the observed data. If there are drastic differences in the true data from the model generated data, our model likely is not very useful. GoF assessments are more complicated using binary data, like detection-nondetection used in occupancy models, as standard approaches are not valid assessments for binary data [@broms2016model, mccullagh2019]. Thus, any approach to assess model fit for detection-nondetection data must bin the raw values in some manner, and then perform a model fit assessment on the binned values. There are numerous ways we could envision binning the raw detection-nondetection values. This is an area of active development in the occupancy modeling literature. 

In `spOccupancy`, model fitted values are calculated directly by the model fitting function (i.e., in this case, `PGOcc`) and can be extracted from the resulting model object using the `fitted` function for subsequent analysis. The resulting model object is sent as input to the `ppcOcc` function, along with a fit statistic (`fit.stat`), sub-sample specifying the samples to use (`sub.sample`), and how to group the data (`group`). Currently supported fit statistics include the Freeman-Tukey statistic and the Chi-Square statistic (`freeman-tukey` or `chi-square`, respectively). Currently, `ppcOcc` allows the use to group the data by row (site; `group = 1`) or column (replicate; `group = 2`). `ppcOcc` will then return a set of posterior samples for the fit statistic (or discrepancy measure) using the observed data (`fit.y`) and model generated data set (`fit.y.rep`), summed across all data points. These values can be used with the `summary` function to generate a Bayesian p-value. Bayesian p-values are sensitive to individual values, so we should also explore the discrepancy measures for each "grouped" data point. `ppcOcc` returns a matrix of posterior quantiles for the fit statistic for both the observed and model generated data for each "grouped" data point. 

We next perform a posterior predictive check using the Freeman-Tukey statistic grouping the data by sites. We summarize the posterior predictive check with the `summary` function, which reports a Bayesian p-value. A Bayesian p-value that hovers around 0.5 indicates adequate model fit, while values less than 0.1 or greater than 0.9 suggest our model does not fit the data well. 

```{r}
ppc.out <- ppcOcc(out, fit.stat = 'freeman-tukey',
		  sub.sample = list(start = round(.10 * n.samples), 
				    end = n.samples), 
		  group = 1)
summary(ppc.out)
```

The Bayesian p-value is the proportion of the posterior samples of the fit statistic of the model generated data that are greater than the corresponding fit statistic of the true data, summed across all "grouped" data points. We can create a visual representation of the Bayesian p-value as follows, which is highly motivated by kery and royle. 

```{r, fig.width = 6, fig.height = 6}
ppc.df <- data.frame(fit = ppc.out$fit.y, 
		     fit.rep = ppc.out$fit.y.rep, 
		     color = 'lightskyblue1')
ppc.df$color[ppc.df$fit.rep > ppc.df$fit] <- 'lightsalmon'
plot(ppc.df$fit, ppc.df$fit.rep, bg = ppc.df$color, pch = 21, 
     ylab = 'Fit', xlab = 'True')
lines(ppc.df$fit, ppc.df$fit, col = 'black')
```

However, relying solely on the Bayesian p-value as an assessment of model fit is not always a great option, as individual data points can have an overbearing influence on the resulting summary value. Instead of summing across all data points for a single discrepancy measure, `ppcOcc` also allows you to explore discrepancy measures on a "grouped" point by point basis, which allows us to better figure out where our model fits well and where it does not. The resulting `ppcOcc` object will contain the objects `fit.y.group.quants` and `fit.y.rep.group.quants`, which contains quantiles of the posterior distributions for the discrepancy measures of each grouped data point. Below we plot the difference in the discrepancy measure between the fitted and true data across each of the sites. 

```{r}
diff.fit <- ppc.out$fit.y.rep.group.quants[3, ] - ppc.out$fit.y.group.quants[3, ]
plot(diff.fit, pch = 19, xlab = 'Site ID', ylab = 'Fitted - True Discrepancy')
```

We see there are a few sites where the true discrepancy is much larger than the discrepancy under the fitted data. Here we will ignore this, but in a real analysis we would explore these sites further to see what could explain this pattern (e.g., are the sites close together in space?). 

### Model Selection using WAIC

### Prediction

## References {-}

